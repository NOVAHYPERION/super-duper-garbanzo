steps:
- name: gcr.io/google.com/cloudsdktool/cloud-sdk
  id: Deploy
  entrypoint: bash
  args: [ '-c', 'if [ "$BRANCH_NAME" == "develop" ]; then echo "$BRANCH_NAME" && gsutil -m rsync -d -r ./src gs://${_DESTINATION_BUCKET} && gsutil -m rsync -d -r ./dags gs://${_COMPOSER_BUCKET}/dags; else echo "Working on $BRANCH_NAME"; fi']
- name: gcr.io/cloud-builders/gcloud
  args: ['composer', 'environments', 'run', '${_COMPOSER_ENV_NAME}', '--location', '${_COMPOSER_REGION}', 'trigger_dag', '--', '${_COMPOSER_DAG_NAME}', '--run_id=$BUILD_ID']
  id: 'trigger-pipeline-execution'
substitutions:
  _COMPOSER_BUCKET: us-central1-bcs-global-comm-fb7c3617-bucket
  _DESTINATION_BUCKET: demobuckey
  _COMPOSER_ENV_NAME: data-pipeline-composer
  _COMPOSER_REGION: us-central1
  _COMPOSER_DAG_NAME: composer_dataflow_dag
# - name: gcr.io/google.com/cloudsdktool/cloud-sdk
#   id: Deploy
#   entrypoint: bash
#   args: [ '-c', 'if [ "$BRANCH_NAME" == "develop" ]; then echo "$BRANCH_NAME" && gsutil -m rsync -d -r ./src gs://${_DESTINATION_BUCKET}; else echo "Working on $BRANCH_NAME"; fi']
# substitutions:
#   _DESTINATION_BUCKET: demo_inputfiles
options:
  logging: CLOUD_LOGGING_ONLY