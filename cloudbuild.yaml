steps:
- name: gcr.io/google.com/cloudsdktool/cloud-sdk
  id: Deploy
  entrypoint: bash
  args: [ '-c', 'if [ "$BRANCH_NAME" == "develop" ]; then echo "$BRANCH_NAME" && gsutil -m rsync -d -r ./src gs://${_DESTINATION_BUCKET} && gsutil -m rsync -d -r ./dags gs://${_COMPOSER_BUCKET}/dags; else echo "Working on $BRANCH_NAME"; fi']
- name: gcr.io/cloud-builders/gcloud
  id: MAKEADAJOBNOW
  args: ['dataflow', 'jobs', 'run', 'MAKEADAJOB', '--gcs-location', 'gs://dataflow-templates-us-central1/latest/Stream_GCS_Text_to_BigQuery', '--region', 'us-central1', '--staging-location', 'gs://demo_input/tmp/', '--parameters', 'javascriptTextTransformGcsPath=gs://demo_input/transformCSVtoJSON.js,JSONPath=gs://demo_input/jsonSchema.json,javascriptTextTransformFunctionName=transformCSVtoJSON,outputTable=gold-mode-329516:demotDaata.demotime,inputFilePattern=gs://demo_input/inputFile.txt,bigQueryLoadingTemporaryDirectory=gs://demo_input/tmp/']
substitutions:
  _COMPOSER_BUCKET: demo_input
  _DESTINATION_BUCKET: demo_input
  _COMPOSER_ENV_NAME: data-pipeline-composer
  _COMPOSER_REGION: us-central1
  _COMPOSER_DAG_NAME: composer_dataflow_dag
# - name: gcr.io/google.com/cloudsdktool/cloud-sdk
#   id: Deploy
#   entrypoint: bash
#   args: [ '-c', 'if [ "$BRANCH_NAME" == "develop" ]; then echo "$BRANCH_NAME" && gsutil -m rsync -d -r ./src gs://${_DESTINATION_BUCKET}; else echo "Working on $BRANCH_NAME"; fi']
# substitutions:
#   _DESTINATION_BUCKET: demo_inputfiles
options:
  logging: CLOUD_LOGGING_ONLY
